{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we need to create a function for calculating distance \n",
    "We'll use Minkowski distance as it as generalized equation for different type of distances\n",
    "![minkowski distance formula](minkowski.png)\n",
    "for p=1, it is called Manhattan Distance\n",
    "for p=2, it is called Eucledian Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mink_dist(m,n,p):\n",
    "    length=len(m)\n",
    "    summation=0\n",
    "    \n",
    "    for i in range(length):\n",
    "        mod_val=abs(m[i]-n[i])\n",
    "        root_val=mod_val**p\n",
    "        summation=summation + root_val\n",
    "        \n",
    "    minkowski_dist= summation**(1/p)\n",
    "    return minkowski_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,x_train,y_train,p,k):\n",
    "    Y_pred=[]\n",
    "    \n",
    "    for i in range(len(x_test)):           \n",
    "        #----------------------------------------------------------------------\n",
    "        #here we find distance of current test point with complete dataset\n",
    "        distances = np.array([mink_dist(x_test[i], x_t,p) for x_t in x_train])\n",
    "        indices_sorted = distances.argsort()[:k]\n",
    "        ##argsort returns indices of a sorted array\n",
    "        #----------------------------------------------------------------------\n",
    "        #here we make a dictionary and count labelclass corresponding to each distance\n",
    "        vote = {}\n",
    "        for index in indices_sorted:\n",
    "            if y_train[index] in vote:\n",
    "                vote[y_train[index]] += 1\n",
    "            else:\n",
    "                vote[y_train[index]] = 1\n",
    "        #----------------------------------------------------------------------\n",
    "        #here we sort our dictionary\n",
    "        sorted_vote = sorted(vote.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        Y_pred.append(sorted_vote[0][0])\n",
    "        #----------------------------------------------------------------------\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "##we will use iris data for verifying our algorithm\n",
    "iris = datasets.load_iris()\n",
    "X= np.array(iris.data)\n",
    "y = np.array(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(X,y,stratify=y,random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (38, 4), (112,), (38,))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to test our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=predict(x_test,x_train,y_train,p=1,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare this with truth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(res,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sklearn to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=knn(n_neighbors=5,p=1)\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
